"""
í›ˆë ¨ëœ ë¶ˆê½ƒ ê°ì§€ ëª¨ë¸ë¡œ ë™ì˜ìƒ ì²˜ë¦¬
Process Videos with Trained Fire Detection Model
"""

import cv2
import torch
from ultralytics import YOLO
import numpy as np
import argparse
import os
from pathlib import Path
import time
from typing import List

def check_gpu_status():
    """GPU ìƒíƒœ í™•ì¸ ë° ì •ë³´ ì¶œë ¥"""
    gpu_available = torch.cuda.is_available()
    
    if gpu_available:
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        compute_cap = torch.cuda.get_device_capability(0)
        
        print(f"ğŸ–¥ï¸  GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        print(f"âš¡ Compute Capability: {compute_cap[0]}.{compute_cap[1]}")
        
        if compute_cap[0] >= 7:
            print("ğŸš€ Tensor Core ì§€ì›")
        
        return True
    else:
        print("ğŸ–¥ï¸  GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
        return False

def optimize_model_for_gpu(model, use_gpu=True):
    """GPU ìµœì í™” ì ìš©"""
    device = 'cuda' if torch.cuda.is_available() and use_gpu else 'cpu'
    
    if device == 'cuda':
        print("ğŸš€ GPU ìµœì í™” ì ìš© ì¤‘...")
        model.to(device)
        torch.cuda.empty_cache()
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        print("   âœ… GPU ìµœì í™” ì™„ë£Œ")
        
        # GPU ì›Œë°ì—…
        print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
        try:
            dummy_input = torch.zeros((640, 640, 3), dtype=torch.uint8, device='cpu')
            with torch.no_grad():
                _ = model(dummy_input, verbose=False)
            torch.cuda.synchronize()
            print("   âœ… GPU ì›Œë°ì—… ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸  ì›Œë°ì—… ê±´ë„ˆëœ€: {str(e)}")
    else:
        print("ğŸ”§ CPU ëª¨ë“œ")
        torch.set_num_threads(min(torch.get_num_threads(), 8))
    
    return device

def process_single_video(
    input_video_path: str,
    output_video_path: str,
    model,
    device: str,
    confidence: float = 0.5
):
    """
    ë‹¨ì¼ ë™ì˜ìƒ ì²˜ë¦¬
    
    Args:
        input_video_path: ì…ë ¥ ë™ì˜ìƒ ê²½ë¡œ
        output_video_path: ì¶œë ¥ ë™ì˜ìƒ ê²½ë¡œ
        model: YOLO ëª¨ë¸
        device: ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')
        confidence: ì‹ ë¢°ë„ ì„ê³„ê°’
    """
    
    print(f"\nğŸ“¹ ì²˜ë¦¬ ì¤‘: {Path(input_video_path).name}")
    print("-" * 60)
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜¤ë¥˜: ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_video_path}")
        return False
    
    # ë¹„ë””ì˜¤ ì†ì„±
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"ğŸ“º ë™ì˜ìƒ ì •ë³´:")
    print(f"   - í•´ìƒë„: {width}x{height}")
    print(f"   - FPS: {fps}")
    print(f"   - ì´ í”„ë ˆì„: {total_frames}")
    
    # ë¹„ë””ì˜¤ ë¼ì´í„°
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    
    frame_count = 0
    fire_detected_frames = 0
    processing_times = []
    inference_times = []
    total_start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            frame_start_time = time.time()
            
            # ì¶”ë¡ 
            inference_start = time.time()
            
            if device == 'cuda':
                results = model(frame, conf=confidence, verbose=False, device=device)
                torch.cuda.synchronize()
            else:
                results = model(frame, conf=confidence, verbose=False, device=device)
            
            inference_time = time.time() - inference_start
            inference_times.append(inference_time)
            
            # ë¶ˆê½ƒ ê°ì§€ ì—¬ë¶€ í™•ì¸
            detections = results[0].boxes
            if len(detections) > 0:
                fire_detected_frames += 1
            
            # ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
            annotated_frame = results[0].plot()
            
            # ë¶ˆê½ƒ ê°ì§€ ì‹œ ê²½ê³  í…ìŠ¤íŠ¸ ì¶”ê°€
            if len(detections) > 0:
                cv2.putText(
                    annotated_frame,
                    "ğŸ”¥ FIRE DETECTED!",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1.0,
                    (0, 0, 255),
                    2
                )
            
            # ì²˜ë¦¬ëœ í”„ë ˆì„ ì €ì¥
            out.write(annotated_frame)
            
            frame_time = time.time() - frame_start_time
            processing_times.append(frame_time)
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if frame_count % 30 == 0 or frame_count == total_frames:
                progress = (frame_count / total_frames) * 100
                avg_inference = np.mean(inference_times[-30:]) * 1000
                avg_fps = 1 / np.mean(processing_times[-30:]) if processing_times else 0
                
                print(f"ğŸ“Š ì§„í–‰: {progress:.1f}% | âš¡ {avg_inference:.1f}ms | ğŸ¬ {avg_fps:.1f} FPS | ğŸ”¥ ê°ì§€: {fire_detected_frames}/{frame_count}", end="")
                
                if device == 'cuda':
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    print(f" | ğŸ’¾ {gpu_memory:.1f}GB")
                else:
                    print()
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False
    
    finally:
        cap.release()
        out.release()
        
        if device == 'cuda':
            torch.cuda.empty_cache()
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸
        total_time = time.time() - total_start_time
        if frame_count > 0:
            avg_fps = frame_count / total_time
            avg_inference = np.mean(inference_times) * 1000
            fire_percentage = (fire_detected_frames / frame_count) * 100
            
            print(f"\nğŸ“ˆ ì²˜ë¦¬ ì™„ë£Œ:")
            print(f"   â±ï¸  ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"   ğŸ¯ í‰ê·  FPS: {avg_fps:.2f}")
            print(f"   âš¡ í‰ê·  ì¶”ë¡ : {avg_inference:.1f}ms")
            print(f"   ğŸ”¥ ë¶ˆê½ƒ ê°ì§€ìœ¨: {fire_percentage:.1f}% ({fire_detected_frames}/{frame_count} í”„ë ˆì„)")
            print(f"   ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_video_path}")
    
    return True

def process_multiple_videos(
    video_paths: List[str],
    model_path: str,
    output_dir: str = "fire_detected_videos",
    confidence: float = 0.5,
    use_gpu: bool = True
):
    """
    ì—¬ëŸ¬ ë™ì˜ìƒì„ ë°°ì¹˜ ì²˜ë¦¬
    
    Args:
        video_paths: ì²˜ë¦¬í•  ë™ì˜ìƒ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        model_path: í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        confidence: ì‹ ë¢°ë„ ì„ê³„ê°’
        use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
    """
    
    print("ğŸ”¥ ë¶ˆê½ƒ ê°ì§€ ë™ì˜ìƒ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    
    # GPU ìƒíƒœ í™•ì¸
    gpu_available = check_gpu_status()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_path}")
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"\nğŸ¤– ëª¨ë¸ ë¡œë”©: {model_path}")
    model_start_time = time.time()
    model = YOLO(model_path)
    
    # GPU ìµœì í™”
    device = optimize_model_for_gpu(model, use_gpu and gpu_available)
    
    model_load_time = time.time() - model_start_time
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({model_load_time:.2f}ì´ˆ)")
    
    # ê° ë™ì˜ìƒ ì²˜ë¦¬
    total_start = time.time()
    success_count = 0
    
    for i, video_path in enumerate(video_paths, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“¹ ë™ì˜ìƒ {i}/{len(video_paths)}")
        
        if not os.path.exists(video_path):
            print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_path}")
            continue
        
        # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
        video_name = Path(video_path).stem
        output_video = output_path / f"{video_name}_fire_detected.mp4"
        
        # ë™ì˜ìƒ ì²˜ë¦¬
        success = process_single_video(
            input_video_path=video_path,
            output_video_path=str(output_video),
            model=model,
            device=device,
            confidence=confidence
        )
        
        if success:
            success_count += 1
    
    # ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ
    total_time = time.time() - total_start
    
    print(f"\n{'='*60}")
    print(f"âœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼: {success_count}/{len(video_paths)} ì„±ê³µ")
    print(f"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time/60:.1f}ë¶„")
    print(f"ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {output_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í›ˆë ¨ëœ ë¶ˆê½ƒ ê°ì§€ ëª¨ë¸ë¡œ ë™ì˜ìƒ ì²˜ë¦¬')
    parser.add_argument('--model', '-m', type=str, required=True,
                       help='í›ˆë ¨ëœ YOLO ëª¨ë¸ ê²½ë¡œ (ì˜ˆ: fire_detection_runs/fire_model/weights/best.pt)')
    parser.add_argument('--videos', '-v', type=str, nargs='+',
                       help='ì²˜ë¦¬í•  ë™ì˜ìƒ íŒŒì¼ë“¤ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)')
    parser.add_argument('--video-dir', type=str,
                       help='ë™ì˜ìƒì´ ìˆëŠ” ë””ë ‰í† ë¦¬ (ëª¨ë“  .mp4 íŒŒì¼ ì²˜ë¦¬)')
    parser.add_argument('--output-dir', '-o', type=str, default='fire_detected_videos',
                       help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: fire_detected_videos)')
    parser.add_argument('--confidence', '-c', type=float, default=0.5,
                       help='ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.5)')
    parser.add_argument('--no-gpu', action='store_true',
                       help='GPU ì‚¬ìš© ì•ˆí•¨')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    if not os.path.exists(args.model):
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.model}")
        return
    
    # ì²˜ë¦¬í•  ë™ì˜ìƒ ëª©ë¡ ìƒì„±
    video_paths = []
    
    if args.videos:
        video_paths.extend(args.videos)
    
    if args.video_dir:
        video_dir = Path(args.video_dir)
        if video_dir.exists():
            video_paths.extend([str(f) for f in video_dir.glob('*.mp4')])
            video_paths.extend([str(f) for f in video_dir.glob('*.avi')])
            video_paths.extend([str(f) for f in video_dir.glob('*.mov')])
        else:
            print(f"âš ï¸  ê²½ê³ : ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.video_dir}")
    
    if not video_paths:
        print("âŒ ì˜¤ë¥˜: ì²˜ë¦¬í•  ë™ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   --videos ë˜ëŠ” --video-dir ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        return
    
    # ì¤‘ë³µ ì œê±°
    video_paths = list(set(video_paths))
    
    print(f"ğŸ“‹ ì²˜ë¦¬í•  ë™ì˜ìƒ ({len(video_paths)}ê°œ):")
    for vp in video_paths:
        print(f"   - {Path(vp).name}")
    
    # ë™ì˜ìƒ ì²˜ë¦¬ ì‹¤í–‰
    process_multiple_videos(
        video_paths=video_paths,
        model_path=args.model,
        output_dir=args.output_dir,
        confidence=args.confidence,
        use_gpu=not args.no_gpu
    )

if __name__ == "__main__":
    # ì¸ì ì—†ì´ ì‹¤í–‰ ì‹œ assets í´ë”ì˜ ë™ì˜ìƒ ìë™ ì²˜ë¦¬
    import sys
    
    if len(sys.argv) == 1:
        print("ğŸ”¥ ë¶ˆê½ƒ ê°ì§€ ë™ì˜ìƒ ì²˜ë¦¬ í”„ë¡œê·¸ë¨")
        print("\nğŸ“– ì‚¬ìš© ì˜ˆì‹œ:")
        print("python process_fire_videos.py --model fire_detection_runs/fire_model/weights/best.pt --video-dir assets")
        print("python process_fire_videos.py --model best.pt --videos video1.mp4 video2.mp4")
        print("python process_fire_videos.py --model best.pt --video-dir assets --confidence 0.7")
        
        # ìë™ ì‹¤í–‰ ì‹œë„
        assets_dir = Path("assets")
        if assets_dir.exists():
            video_files = list(assets_dir.glob("*.mp4"))
            if video_files:
                print(f"\nğŸ“¹ assets í´ë”ì—ì„œ {len(video_files)}ê°œì˜ ë™ì˜ìƒ ë°œê²¬:")
                for vf in video_files:
                    print(f"   - {vf.name}")
                
                # ìµœì‹  í›ˆë ¨ ëª¨ë¸ ì°¾ê¸°
                runs_dir = Path("fire_detection_runs")
                if runs_dir.exists():
                    best_models = list(runs_dir.glob("*/weights/best.pt"))
                    if best_models:
                        latest_model = max(best_models, key=lambda p: p.stat().st_mtime)
                        print(f"\nğŸ¤– ìµœì‹  ëª¨ë¸ ë°œê²¬: {latest_model}")
                        print(f"\nìë™ ì‹¤í–‰ì„ ì›í•˜ì‹œë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”:")
                        print(f"python process_fire_videos.py --model {latest_model} --video-dir assets")
    else:
        main()
