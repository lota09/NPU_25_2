import torch

def check_gpu_status():
    """GPU ìƒíƒœ í™•ì¸"""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸ–¥ï¸  GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        print(f"âœ… CUDA ë²„ì „: {torch.version.cuda}")
        return True
    else:
        print("âš ï¸  GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.")
        return False
    
if __name__ == "__main__":
    check_gpu_status()