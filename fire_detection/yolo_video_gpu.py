import cv2
import torch
from ultralytics import YOLO
import numpy as np
import argparse
import os
from pathlib import Path
import time

def check_gpu_status():
    """GPU ìƒíƒœ í™•ì¸ ë° ì •ë³´ ì¶œë ¥"""
    gpu_available = torch.cuda.is_available()
    
    if gpu_available:
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        compute_cap = torch.cuda.get_device_capability(0)
        
        print(f"ğŸ–¥ï¸  GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        print(f"âš¡ Compute Capability: {compute_cap[0]}.{compute_cap[1]}")
        
        # Tensor Core ì§€ì› í™•ì¸
        if compute_cap[0] >= 7:
            print("ğŸš€ Tensor Core ì§€ì› - í˜¼í•© ì •ë°€ë„(FP16) ì‚¬ìš© ê°€ëŠ¥")
        
        return True, gpu_name
    else:
        print("ğŸ–¥ï¸  GPU: ì‚¬ìš© ë¶ˆê°€ (CPU ëª¨ë“œ)")
        return False, "CPU"

def optimize_model_for_gpu(model, use_gpu=True):
    """GPU ìµœì í™” ì ìš©"""
    device = 'cuda' if torch.cuda.is_available() and use_gpu else 'cpu'
    
    if device == 'cuda':
        print("ğŸš€ GPU ìµœì í™” ì ìš© ì¤‘...")
        
        # GPUë¡œ ëª¨ë¸ ì´ë™
        model.to(device)
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
        
        # CUDNN ìµœì í™”
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        print("   âœ… GPU ìµœì í™” ì„¤ì • ì™„ë£Œ")
        
        # GPU ì›Œë°ì—… (FP16 ì—†ì´)
        print("ğŸ”¥ GPU ì›Œë°ì—… ì¤‘...")
        try:
            dummy_input = torch.zeros((640, 640, 3), dtype=torch.uint8, device='cpu')
            with torch.no_grad():
                _ = model(dummy_input, verbose=False)
            torch.cuda.synchronize()
            print("   âœ… GPU ì›Œë°ì—… ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸  ì›Œë°ì—… ê±´ë„ˆëœ€: {str(e)}")
        
    else:
        print("ğŸ”§ CPU ëª¨ë“œ - ìŠ¤ë ˆë“œ ìµœì í™” ì ìš©")
        # CPU ìµœì í™”
        torch.set_num_threads(min(torch.get_num_threads(), 8))
    
    return device

def process_video_with_yolo(input_video_path, output_video_path, model_path='yolov10n.pt', confidence=0.5, use_gpu=True):
    """
    YOLOv10ì„ ì‚¬ìš©í•˜ì—¬ ë™ì˜ìƒì—ì„œ ë¬¼ì²´ì¸ì‹ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        input_video_path (str): ì…ë ¥ ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        output_video_path (str): ì¶œë ¥ ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        model_path (str): YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: 'yolov10n.pt')
        confidence (float): ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.5)
        use_gpu (bool): GPU ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    """
    
    print(f"ğŸ¯ YOLOv10 ë™ì˜ìƒ ë¬¼ì²´ì¸ì‹ (GPU ê°€ì†)")
    print("=" * 50)
    
    # GPU ìƒíƒœ í™•ì¸
    gpu_available, gpu_info = check_gpu_status()
    
    # YOLO ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
    model_start_time = time.time()
    
    model = YOLO(model_path)
    
    # GPU ìµœì í™” ì ìš©
    device = optimize_model_for_gpu(model, use_gpu and gpu_available)
    
    model_load_time = time.time() - model_start_time
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({model_load_time:.2f}ì´ˆ)")
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„±
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        print(f"âŒ ì˜¤ë¥˜: ë™ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_video_path}")
        return
    
    # ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"ğŸ“º ë™ì˜ìƒ ì •ë³´:")
    print(f"   - í•´ìƒë„: {width}x{height}")
    print(f"   - FPS: {fps}")
    print(f"   - ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"   - ì˜ˆìƒ ì†Œìš”ì‹œê°„: {total_frames / fps / (10 if device == 'cuda' else 2):.1f}ì´ˆ")
    
    # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))
    
    frame_count = 0
    processing_times = []
    inference_times = []
    total_start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            frame_start_time = time.time()
            
            # GPU ìµœì í™” ì¶”ë¡ 
            inference_start = time.time()
            
            if device == 'cuda':
                # GPUì—ì„œ ì•ˆì „í•œ ì¶”ë¡ 
                results = model(frame, conf=confidence, verbose=False, device=device)
                torch.cuda.synchronize()  # GPU ë™ê¸°í™”
            else:
                results = model(frame, conf=confidence, verbose=False, device=device)
            
            inference_time = time.time() - inference_start
            inference_times.append(inference_time)
            
            # ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°
            annotated_frame = results[0].plot()
            
            # ì²˜ë¦¬ëœ í”„ë ˆì„ì„ ì¶œë ¥ ë¹„ë””ì˜¤ì— ì“°ê¸°
            out.write(annotated_frame)
            
            frame_time = time.time() - frame_start_time
            processing_times.append(frame_time)
            
            # ì§„í–‰ë¥  ë° ì„±ëŠ¥ í‘œì‹œ
            if frame_count % 30 == 0 or frame_count == total_frames:
                progress = (frame_count / total_frames) * 100
                avg_inference = np.mean(inference_times[-30:]) * 1000  # ms
                avg_fps = 1 / np.mean(processing_times[-30:]) if processing_times else 0
                
                print(f"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% | âš¡ ì¶”ë¡ : {avg_inference:.1f}ms | ğŸ¬ FPS: {avg_fps:.1f}", end="")
                
                if device == 'cuda':
                    gpu_memory = torch.cuda.memory_allocated() / 1024**3
                    gpu_usage = (gpu_memory / torch.cuda.get_device_properties(0).total_memory * 1024**3) * 100
                    print(f" | ğŸ’¾ GPU: {gpu_memory:.1f}GB ({gpu_usage:.1f}%)")
                else:
                    print()
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        cap.release()
        out.release()
        cv2.destroyAllWindows()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if device == 'cuda':
            torch.cuda.empty_cache()
        
        # ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸
        total_time = time.time() - total_start_time
        if frame_count > 0:
            avg_fps = frame_count / total_time
            avg_inference = np.mean(inference_times) * 1000
            speedup = avg_fps / fps  # ì‹¤ì‹œê°„ ëŒ€ë¹„ ì†ë„
            
            print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
            print(f"   â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"   ğŸ¯ í‰ê·  FPS: {avg_fps:.2f}")
            print(f"   âš¡ í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference:.1f}ms")
            print(f"   ğŸš€ ì‹¤ì‹œê°„ ëŒ€ë¹„ ì†ë„: {speedup:.1f}x")
            print(f"   ğŸ¬ ì²˜ë¦¬ëœ í”„ë ˆì„: {frame_count}/{total_frames}")
            
            if device == 'cuda':
                theoretical_fps = 1000 / avg_inference
                efficiency = (avg_fps / theoretical_fps) * 100
                print(f"   ğŸ“Š GPU íš¨ìœ¨ì„±: {efficiency:.1f}%")
        
        print(f"\nâœ… ë™ì˜ìƒ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_video_path}")

def main():
    parser = argparse.ArgumentParser(description='YOLOv10ì„ ì‚¬ìš©í•œ ë™ì˜ìƒ ë¬¼ì²´ì¸ì‹ (GPU ê°€ì†)')
    parser.add_argument('--input', '-i', type=str, required=True,
                       help='ì…ë ¥ ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', '-o', type=str, 
                       help='ì¶œë ¥ ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: input_filename_gpu_detected.mp4)')
    parser.add_argument('--model', '-m', type=str, default='yolov10n.pt',
                       help='YOLO ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: yolov10n.pt)')
    parser.add_argument('--confidence', '-c', type=float, default=0.5,
                       help='ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.5)')
    parser.add_argument('--no-gpu', action='store_true',
                       help='GPU ì‚¬ìš© ì•ˆí•¨ (CPUë§Œ ì‚¬ìš©)')
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.input):
        print(f"âŒ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.input}")
        return
    
    # ì¶œë ¥ íŒŒì¼ëª… ì„¤ì •
    if args.output is None:
        input_path = Path(args.input)
        suffix = "_gpu_detected" if not args.no_gpu and torch.cuda.is_available() else "_cpu_detected"
        output_filename = f"{input_path.stem}{suffix}{input_path.suffix}"
        args.output = str(input_path.parent / output_filename)
    
    use_gpu = not args.no_gpu
    
    print(f"ğŸ¯ YOLOv10 ë™ì˜ìƒ ë¬¼ì²´ì¸ì‹")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {args.input}")
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {args.output}")
    print(f"ğŸ¤– ëª¨ë¸: {args.model}")
    print(f"ğŸ“Š ì‹ ë¢°ë„ ì„ê³„ê°’: {args.confidence}")
    print(f"âš¡ GPU ì‚¬ìš©: {'ì˜ˆ' if use_gpu and torch.cuda.is_available() else 'ì•„ë‹ˆì˜¤'}")
    print("=" * 60)
    
    # ë™ì˜ìƒ ì²˜ë¦¬ ì‹¤í–‰
    process_video_with_yolo(
        input_video_path=args.input,
        output_video_path=args.output,
        model_path=args.model,
        confidence=args.confidence,
        use_gpu=use_gpu
    )

if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ ì˜ˆì œ
    if len(os.sys.argv) == 1:
        print("ğŸš€ YOLOv10 ë™ì˜ìƒ ë¬¼ì²´ì¸ì‹ í”„ë¡œê·¸ë¨ (GPU ê°€ì†)")
        print("\nğŸ“– ì‚¬ìš© ì˜ˆì‹œ:")
        print("python yolo_video_detection.py --input video1.mp4")
        print("python yolo_video_detection.py --input video1.mp4 --output result.mp4")
        print("python yolo_video_detection.py --input video1.mp4 --model yolov10s.pt --confidence 0.7")
        print("python yolo_video_detection.py --input video1.mp4 --no-gpu  # CPUë§Œ ì‚¬ìš©")
        
        # GPU ìƒíƒœ í™•ì¸ ë° í‘œì‹œ
        print("\n" + "=" * 60)
        gpu_available, gpu_info = check_gpu_status()
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ë™ì˜ìƒ íŒŒì¼ë“¤ í‘œì‹œ
        current_dir = Path(".")
        video_files = list(current_dir.glob("*.mp4")) + list(current_dir.glob("*.avi")) + list(current_dir.glob("*.mov"))
        
        # ì›ë³¸ ë™ì˜ìƒ íŒŒì¼ë§Œ í•„í„°ë§
        original_videos = []
        for video_file in video_files:
            if not any(keyword in video_file.stem.lower() for keyword in ['detected', 'gpu', 'cpu', 'optimized', 'quick', 'batch']):
                original_videos.append(video_file)
        
        if original_videos:
            print(f"\nğŸ“¹ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ì›ë³¸ ë™ì˜ìƒ íŒŒì¼ë“¤:")
            for video_file in original_videos:
                print(f"   - {video_file.name}")
            
            # ì²« ë²ˆì§¸ ë™ì˜ìƒ íŒŒì¼ë¡œ ìë™ ì‹¤í–‰
            input_video = str(original_videos[0])
            suffix = "_gpu_demo" if gpu_available else "_cpu_demo"
            output_video = f"{original_videos[0].stem}{suffix}{original_videos[0].suffix}"
            
            print(f"\nğŸ¬ ì²« ë²ˆì§¸ ë™ì˜ìƒ íŒŒì¼ë¡œ GPU ê°€ì† ì‹¤í–‰: {input_video}")
            process_video_with_yolo(input_video, output_video, use_gpu=True)
        else:
            print("\nâŒ ì›ë³¸ ë™ì˜ìƒ íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        main()