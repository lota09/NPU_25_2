### **4.1.1. 화재 오탐 감소 및 과적합 방지**

- **Problem** :
    - **일상 사물 오인식**: 초기 모델(v7_original_200epoch_16batch)에서 콘센트, 전구, 전열기 등 밝은 빛을 내는 일상적인 사물을 불꽃(flame)으로 오탐하는 False Positive 문제가 발생했다. 특히 벽면 콘센트의 LED 표시등이나 전자기기의 전원 램프를 화재로 잘못 판단하는 경우가 자주 발생했다.
    - **제한적인 학습 데이터**: 단일 데이터셋(Home Fire Dataset)만으로 학습하여 다양한 조명 조건, 촬영 각도, 화재 단계(초기/중기/말기)에 대한 일반화 성능이 부족했다.
    - **과적합(Overfitting) 발견**: 200 epoch까지 학습한 모델은 Validation set에서 mAP@0.5 = 0.9531로 매우 높은 성능을 보였으나, 실제 환경(학습되지 않은 동영상)에서 테스트 시 콘센트를 불꽃으로 오탐하는 문제가 발생했다. 반면 100 epoch 모델은 Validation mAP@0.5 = 0.7824(우측)로 낮았지만 실제 환경에서 오탐이 없었다.
    
    ![PR_curve.png](attachment:927ea51c-b8f4-44e5-93c5-6b2d3281c5a2:PR_curve.png)
    
    ▲  200 epoch, 16 Batch (mAP@0.5 = 0.9531)
    
    ![PR_curve.png](attachment:893d660a-914d-4129-b5d4-be263ba0e73f:PR_curve.png)
    
    ▲ 100 epoch, 16 Batch (mAP@0.5 = 0.9531)
    
    - **과적합의 원인**:
        1. **데이터셋 분포 편향**: 학습/검증 데이터는 주로 "화재 장면"만 포함하여 모델이 "밝은 빛 = 불꽃"이라는 과도한 상관관계를 학습했다. 실제 가정 환경에는 콘센트 LED, 전구, 가전제품 등 "비화재 밝은 빛"이 존재하지만, 이러한 케이스가 학습 데이터에 부족했다.
        2. **Validation Set의 한계**: Train/Val/Test 모두 같은 "화재 데이터셋"에서 분할되어 동일한 분포를 공유한다. 따라서 Validation 성능이 높아도 실제 배포 환경(일상 가정)에서의 일반화 성능을 보장하지 못한다.
        3. **과학습(Overlearning)**: 200 epoch에서 모델이 화재의 본질적 특징(불규칙한 형태, 움직임, 색상 변화)보다 데이터셋 특유의 패턴(특정 밝기, 특정 배경)을 과도하게 학습하여 실전에서 일반화 실패를 보였다.
- **Solution** :
    1. **데이터셋 확장 및 병합(Merged Dataset)**: 가정 내 화재 데이터셋(Home Fire Dataset)과 공개 화재 데이터셋을 병합하여 학습 데이터의 다양성을 확보했다. 이를 통해 실내/실외, 주간/야간, 다양한 배경과 조명 조건에서의 불꽃과 연기 패턴을 학습할 수 있었다.
    2. **실전 검증 시험 설계 (yolov7_video_compare.py)**: Validation 지표만으로는 실제 성능을 예측할 수 없다는 교훈을 바탕으로, 학습에 사용되지 않은 실제 화재 동영상(bucket11.mp4, printer31.mp4, roomfire41.mp4)을 별도로 확보하여 두 모델(100 epoch vs 200 epoch)의 실전 성능을 직접 비교했다.
        - **목적**: 두 모델 모두 동일한 미학습 데이터에서 화재와 연기를 탐지하는 양상을 관찰하여, 신뢰도 분포와 오탐 가능성(콘센트, 전구 등 일상 사물)을 정성적으로 검증
        - **방법**: 각 동영상에 대해 두 모델의 결과 동영상을 생성하고, 프레임별 Detection 수, 평균 신뢰도, 오탐 케이스를 육안 및 정량 분석
        
        ![printer31_v7_merged_200epoch_16batch.mp4_20251202_152605.422.jpg](attachment:5c6dfc42-0ca8-4443-9e08-bd56795a7fcc:printer31_v7_merged_200epoch_16batch.mp4_20251202_152605.422.jpg)
        
        ▲ 200 epoch, 16 Batch : 콘센트를 85% 신뢰도로 화재로 인식
        
        ![printer31_v7_merged_100epoch_16batch.mp4_20251202_152603.372.jpg](attachment:439e3300-7a18-4ae2-b915-9f2bac63aaac:printer31_v7_merged_100epoch_16batch.mp4_20251202_152603.372.jpg)
        
        ▲ 100 epoch, 16 Batch : 완전히 동일한 프레임에서 콘센트를 화재로 인식하지 않음 (신뢰도 < 50%)
        
        - **핵심 발견**: 200 epoch 모델이 Validation mAP는 높지만(95.31%), 실제 환경에서 콘센트를 0.85 신뢰도로 불꽃 오탐. 100 epoch 모델은 mAP는 낮지만(78.24%) 오탐 전무
    3. **실전 우수 모델 선정**: **v7_merged_100epoch_16batch**를 최종 모델로 채택했다. Validation 지표가 높더라도 실제 배포 환경에서의 일반화 성능은 떨어질 수 있으므로, 반드시 학습되지 않은 실제 데이터로 검증해야 한다는 원칙을 확립했다.
- **Result** :
    - **실전 우수 모델 선정**: 최종 모델로 **v7_merged_100epoch_16batch**를 채택하였다. Validation mAP@0.5는 78.24%로 200 epoch 모델(95.31%)보다 낮지만, 실제 환경에서 콘센트/전구 등 일상 사물에 대한 오탐이 없고, 화재 감지 성능은 200 epoch과 유사하여 실용성이 훨씬 높다.
    - **과적합 vs 일반화 교훈**: 단순히 Validation 지표만 보고 모델을 선택하면 과적합된 모델을 선택할 위험이 있다. 특히 화재 감지처럼 Real-world 환경이 학습 데이터와 크게 다를 수 있는 경우, 반드시 실제 환경에서 직접 테스트하여 오탐률을 확인해야 한다.
        - **성능 비교**:
    
    | 지표 | v7_merged_100epoch | v7_merged_200epoch | 최종 선택 |
    | --- | --- | --- | --- |
    | **Val mAP@0.5** | 0.7824 | 0.9531 | - |
    | **콘센트 오탐** | ❌ 없음 | ⚠️ 발생 (0.75+ 신뢰도) | **100 epoch** |
    | **실제 화재 감지** | ✅ 양호 | ✅ 양호 | 동등 |
    | **일반화 능력** | ✅ 높음 | ❌ 낮음 (과적합) | **100 epoch** |
    - **배포 전략**: 높은 Validation 점수보다 낮은 오탐률이 사용자 신뢰도에 더 중요하므로, 일반화 능력이 검증된 v7_merged_100epoch_16batch를 최종 배포 모델로 확정하였다.

### **4.1.2. 침입 감지 시 일부 기기 미탐지 문제**

- **Problem** :
    - **ARP 응답 누락**: 초기 침입 탐지 시스템에서 네트워크 내 장치를 감지하기 위해 ARP(Address Resolution Protocol) 스캔을 사용했으나, 일부 스마트폰과 IoT 기기가 ARP 요청에 응답하지 않는 문제가 발생했다.
    - **절전 모드 및 프라이버시 기능**: 특히 iOS 기기와 일부 Android 기기는 배터리 절약을 위한 절전 모드나 MAC 주소 랜덤화(Privacy) 기능으로 인해 ARP 테이블에 나타나지 않거나, 응답이 간헐적으로 누락되었다.
    - **거주자 오탐**: 사용자가 집에 있음에도 불구하고 스마트폰이 ARP 스캔에서 감지되지 않아, 시스템이 "재실 없음"으로 판단하여 침입 경보를 발생시키는 오작동이 있었다.
- **Solution** :
    1. **Robust Scan (3단계 정밀 탐지) 도입**: 단순 ARP 스캔의 한계를 극복하기 위해 `user_presence.py` 모듈에 **Passive → Reactive → Active**로 이어지는 3단계 복합 스캔 로직을 구현했다.
        - **1단계 (Passive)**: 리눅스 커널의 ARP 테이블(`ip neighbor show`)을 조회하여 최근 통신 기록이 있는 기기를 즉시 식별한다.
        - **2단계 (Wake-up)**: 기기가 절전 모드이거나 정보가 오래된(STALE) 경우, **UDP Knocking** (더미 패킷 브로드캐스트)을 수행하여 강제로 네트워크 스택을 깨운다.
        - **3단계 (Active)**: 마지막으로 확인된 IP 주소로 **ICMP Ping**을 보내 실제 연결 유무를 최종 검증한다.
    2. **Python `subprocess` 기반 경량화**: 외부의 무거운 라이브러리(Scapy 등) 의존성을 제거하고, 리눅스 자체 명령(`ip`, `ping`)을 파이썬 내부에서 효율적으로 호출하여 시스템 리소스 점유를 최소화했다.
    3. **신뢰 장치 다중 등록**: 단일 기기에 의존하지 않고, 사용자의 스마트폰, 태블릿 등 여러 기기를 `config.json`에 등록하여 그 중 하나라도 감지되면 재실로 판단하는 'OR' 조건을 적용했다.
- **Result** :
    - **절전 모드 기기 탐지 성공**: UDP Knocking을 통해 절전 모드에 진입한 스마트폰(아이폰 포함)을 효과적으로 깨워 탐지할 수 있게 되었으며, 단순 Ping만 보냈을 때보다 재실 판단 정확도가 획기적으로 개선되었다.
    
    ![화면 캡처 2025-12-02 214817.jpg](attachment:245148e3-f9d8-41e5-9e10-75441ca8ba28:화면_캡처_2025-12-02_214817.jpg)
    
    ▲ (개선 전) 간헐적인 응답 누락으로 일부 기기만 탐지됨
    
    ![화면 캡처 2025-12-02 215548.jpg](attachment:ca236a30-d935-46bc-a126-ed85bf34408e:화면_캡처_2025-12-02_215548.jpg)
    
    ▲ (개선 후) Robust Scan 적용 후 모든 기기가 안정적으로 탐지됨
    
    - **오작동 제거**: 사용자가 집에 있음에도 부재중으로 오인하여 경보가 울리는 False Positive 사례가 완전히 해결되었다.
    - **모듈화**: 재실 감지 로직이 `user_presence.py`로 독립되어, 향후 다른 프로젝트나 기능에서도 쉽게 재사용할 수 있게 되었다.
    - **안정적인 재실 판단**: 네트워크 스캔 결과가 일관성 있게 유지되어, 화재 발생 시 "재실 여부"와 결합한 정확한 위험도 판단이 가능해졌다.
### **4.1.3. NPU 포팅 및 추론 최적화 문제**

- **Problem (3단계 - 변환, 컴파일, 추론 단계별 문제)** :
    이 문제는 단순한 포팅 작업이 아니라, **"변환(Conversion) - 컴파일(Compilation) - 추론(Inference)"**의 3단계 전 과정에서 각각 치명적인 오류가 발생한 복합적인 난제였다.
    1.  **변환 단계 (Model Architecture Mismatch)**: YOLOv7의 기본 출력 구조는 FPN(Feature Pyramid Network)의 3개 스케일(P3, P4, P5)이 분리되어 출력된다. 그러나 NPU 컴파일러(DXNN)의 `SURGERY` 단계는 이러한 다중 출력을 단일 그래프로 해석하지 못해 변환을 거부했다.
    2.  **컴파일 단계 (Compiler Version Trap)**: "최신 버전이 가장 좋다"는 일반적인 통념을 따라 최신 `dx_com v2.0.0`을 사용했으나, 타겟 장비(Orange Pi)의 런타임(DXRT v2.9.5)과 호환되지 않는 바이너리를 생성하여 `Unwanted Data Type`이라는 모호한 에러와 함께 로드 자체가 불가능했다.
    3.  **추론 단계 (Signal Distortion)**: 어렵게 포팅에 성공한 초기 모델(Float32)조차 NPU 상에서는 모든 객체의 신뢰도(Confidence)가 **0.18**로 고정되거나, 활성화 함수 변경(LeakyReLU) 시 **1.0**으로 포화(Saturation)되어 화재와 비화재를 전혀 구분할 수 없었다. 이는 NPU가 Float32 연산보다 INT8 양자화 연산에 더 최적화되어 있다는 하드웨어 특성을 간과한 결과였다.

- **Solution (3단계 - 변환, 컴파일, 추론 단계별 문제)** :

    1.  **출력 레이어 재설계 (Architectural Surgery)**: 모델의 끝단(Head)을 수정하여 3개의 스케일 출력을 하나의 거대한 텐서(`[1, 25200, 7]`)로 통합(Concatenation)했다. 이를 통해 NPU 컴파일러가 모델 전체를 하나의 최적화된 서브그래프로 인식하게 만들었다.
    2.  **Downgrade for Compatibility**: 타겟 런타임(DXRT)의 릴리즈 노트를 역추적하여, 최신 컴파일러 대신 가장 호환성이 높은 **v1.60.1** 버전을 찾아내어 적용했다.
    3.  **Opset 12 & INT8 전략 (Golden Example 분석)**: NPU 디바이스에 기본 포함된 예제 파일 `YOLOV7-2.onnx`가 정상 작동하는 것을 확인하고, 해당 모델의 메타데이터를 역분석했다. 그 결과 예제 모델이 **Opset 12**와 **INT8 Quantization**으로 구성되어 있음을 발견하고, 이를 우리 모델에 그대로 적용함으로써 SiLU 활성화 함수의 비선형성 문제를 완벽하게 해결했다.

- **Result (Quantifiable Breakthrough)** :
    단순한 문제 해결을 넘어, 성능과 기능을 동시에 업그레이드하는 결과를 얻었다.

    | 항목 | 초기 시도 (Float32/SiLU) | 최적화 후 (INT8/Golden Path) | 개선 효과 |
    | :--- | :---: | :---: | :---: |
    | **추론 속도** | 63ms | **51ms** | **~19% 속도 향상** |
    | **신뢰도 분포** | 0.18 (고정) | **0.0 ~ 0.95 (정상)** | **탐지 기능 회복** |
    | **메모리 효율** | 낮음 | **높음 (Quantized)** | **최적화** |
    | **기능 확장** | 단일 클래스 | **Fire & Smoke (2-Class)** | **다중 탐지 성공** |

    - **최종 성과**: 이 최적화를 통해 엣지 디바이스(Orange Pi)에서도 **51ms(약 20FPS)**의 속도로 **화재와 연기를 동시에 정밀하게 탐지**할 수 있는 고성능 NPU 파이프라인을 구축했다. 이는 임베디드 AI 개발에서 SW(모델)와 HW(NPU)의 최적화 궁합(`Opset`+`Quantization`)이 얼마나 중요한지를 증명하는 사례다.
