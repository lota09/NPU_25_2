#!/usr/bin/env python3
"""
Fire Detection Real-time Monitoring Script
ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ ì…ë ¥ì—ì„œ í™”ì¬ë¥¼ ê°ì§€í•˜ê³  ì‹œê°„ ê¸°ë°˜ í‰ê·  ì‹ ë¢°ë„ë¡œ ë‹¤ë‹¨ê³„ ì•Œë¦¼ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
Orange Pi DXNN ëª¨ë¸ ì‚¬ìš©
"""

import argparse
import logging
import os
import sys
import time
from collections import deque
from typing import Optional, Tuple

# OpenCV ë°±ì—”ë“œ ì„¤ì • (ë””ìŠ¤í”Œë ˆì´ê°€ ìˆì„ ë•ŒëŠ” xcb ì‚¬ìš©)
if os.environ.get('DISPLAY') is None:
    os.environ['QT_QPA_PLATFORM'] = 'offscreen'

import cv2
import numpy as np
from scipy.special import expit  # sigmoid í•¨ìˆ˜

try:
    from dx_engine import InferenceEngine
except ImportError:
    print("Warning: dx_engine not available. Running in CPU mode.")
    InferenceEngine = None


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FireDetectionMonitor:
        """ì‹œê°„ ê¸°ë°˜ í‰ê·  ì‹ ë¢°ë„ë¥¼ ì‚¬ìš©í•˜ëŠ” í™”ì¬ ê°ì§€ ëª¨ë‹ˆí„°"""
        
        # ì•Œë¦¼ ë“±ê¸‰ ì •ì˜ (Sigmoid ì •ê·œí™” í›„ [0, 1] ë²”ìœ„)
        # Raw logitì„ Sigmoidë¡œ ì •ê·œí™”í•œ ì‹ ë¢°ë„ ê¸°ì¤€
        ALERT_LEVEL = {
            'MONITORING': (0.00, 0.35, 'âœ… ì •ìƒ'),
            'LOW': (0.35, 0.50, 'ğŸŸ¡ ì£¼ì˜'),
            'MEDIUM': (0.50, 0.65, 'ğŸŸ  ê²½ê³ '),
            'HIGH': (0.65, 1.00, 'ğŸ”´ ê¸´ê¸‰ ëŒ€í”¼')
        }
        
        def __init__(
            self,
            model_path: str,
            video_source: str = '/dev/video0',
            time_window: float = 3.0,
            input_size: Tuple[int, int] = (640, 640),
            conf_threshold: float = 0.5,
            use_dxnn: bool = True
        ):
            """
            Args:
                model_path: DXNN ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.dxnn)
                video_source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼)
                time_window: í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° ì‹œê°„ ìœˆë„ìš° (ì´ˆ)
                input_size: ëª¨ë¸ ì…ë ¥ í¬ê¸°
                conf_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
                use_dxnn: DXNN ì‚¬ìš© ì—¬ë¶€
            """
            self.model_path = model_path
            self.video_source = video_source
            self.time_window = time_window
            self.input_size = input_size
            self.conf_threshold = conf_threshold
            self.use_dxnn = use_dxnn and InferenceEngine is not None
            
            # ëª¨ë¸ ë¡œë“œ
            self.engine = None
            if self.use_dxnn:
                self._load_dxnn_model()
            
            # ë¹„ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™”
            self.cap = None
            self.fps = 30
            self._init_video_capture()
            
            # ì‹ ë¢°ë„ ì´ë ¥ (ìµœëŒ€ ì‹œê°„ ìœˆë„ìš°ì— í•´ë‹¹í•˜ëŠ” í”„ë ˆì„ ìˆ˜)
            self.confidence_history = deque(maxlen=int(self.fps * self.time_window))
            self.timestamp_history = deque(maxlen=int(self.fps * self.time_window))
            
            # ìƒíƒœ ì¶”ì 
            self.current_alert_level = 'MONITORING'
            self.last_alert_time = 0
            self.alert_duration = 2.0  # ì•Œë¦¼ ì§€ì† ì‹œê°„ (ì´ˆ)
            
            logger.info(f"Fire Detection Monitor initialized")
            logger.info(f"  - Model: {model_path}")
            logger.info(f"  - Video source: {video_source}")
            logger.info(f"  - Time window: {time_window}s")
            logger.info(f"  - Use DXNN: {self.use_dxnn}")
        
        def _load_dxnn_model(self):
            """DXNN ëª¨ë¸ ë¡œë“œ"""
            try:
                logger.info(f"Loading DXNN model: {self.model_path}")
                start_time = time.time()
                self.engine = InferenceEngine(self.model_path)
                load_time = time.time() - start_time
                logger.info(f"âœ… Model loaded in {load_time:.3f}s")
            except Exception as e:
                logger.error(f"Failed to load DXNN model: {e}")
                self.use_dxnn = False
        
        def _init_video_capture(self):
            """ë¹„ë””ì˜¤ ìº¡ì²˜ ì´ˆê¸°í™”"""
            try:
                # ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
                if self.video_source.isdigit() or self.video_source.startswith('/dev/video'):
                    # ì¹´ë©”ë¼ (ìˆ«ì ë˜ëŠ” /dev/video0 í˜•ì‹)
                    device_index = int(self.video_source) if self.video_source.isdigit() else self.video_source
                    self.cap = cv2.VideoCapture(device_index if isinstance(device_index, int) else self.video_source)
                    logger.info(f"âœ… Camera opened: {self.video_source}")
                    is_camera = True
                else:
                    # ë¹„ë””ì˜¤ íŒŒì¼
                    self.cap = cv2.VideoCapture(self.video_source)
                    logger.info(f"âœ… Video file opened: {self.video_source}")
                    is_camera = False
                
                if not self.cap or not self.cap.isOpened():
                    raise RuntimeError(f"Cannot open video source: {self.video_source}")
                
                # FPS ì •ë³´ íšë“
                self.fps = int(self.cap.get(cv2.CAP_PROP_FPS)) or 30
                logger.info(f"  - FPS: {self.fps}")
                
                # í•´ìƒë„ ì •ë³´ íšë“
                width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                logger.info(f"  - Resolution: {width}x{height}")
                
                # ì¹´ë©”ë¼ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
                if is_camera:
                    logger.info(f"  - Camera Type: {self.cap.get(cv2.CAP_PROP_BACKEND)}")
                    logger.info(f"  - Codec: {self.cap.get(cv2.CAP_PROP_FOURCC)}")
                
            except Exception as e:
                logger.error(f"Failed to initialize video capture: {e}")
                sys.exit(1)
        
        def preprocess_frame(self, frame: np.ndarray) -> np.ndarray:
            """
            í”„ë ˆì„ ì „ì²˜ë¦¬ (YOLO í˜•ì‹)
            - ë¦¬ì‚¬ì´ì§•
            - Float32 ì •ê·œí™”
            - NCHW í¬ë§· ë³€í™˜
            """
            # ì…ë ¥ í”„ë ˆì„ ê²€ì¦
            if frame is None or frame.size == 0:
                logger.warning("Empty frame received")
                return np.zeros((1, 3, self.input_size[0], self.input_size[1]), dtype=np.float32)
            
            # ë¦¬ì‚¬ì´ì§• (ì•„ìŠ¤í™íŠ¸ ë¹„ìœ¨ ìœ ì§€í•˜ë©° íŒ¨ë”©)
            h, w = frame.shape[:2]
            scale = min(self.input_size[0] / w, self.input_size[1] / h)
            
            new_w = int(w * scale)
            new_h = int(h * scale)
            
            resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
            
            # ê²€ì€ìƒ‰ ë°°ê²½ì— íŒ¨ë”©
            padded = np.zeros((self.input_size[1], self.input_size[0], 3), dtype=np.uint8)
            pad_y = (self.input_size[1] - new_h) // 2
            pad_x = (self.input_size[0] - new_w) // 2
            padded[pad_y:pad_y+new_h, pad_x:pad_x+new_w] = resized
            
            # BGR -> RGB
            rgb = cv2.cvtColor(padded, cv2.COLOR_BGR2RGB)
            
            # NCHW í¬ë§·ìœ¼ë¡œ ë³€í™˜ (Float32ë¡œ ì •ê·œí™”)
            img_array = np.asarray(rgb, dtype=np.float32)
            img_array = img_array.transpose(2, 0, 1) / 255.0
            img_array = np.expand_dims(img_array, axis=0)  # ë°°ì¹˜ ì¶”ê°€
            
            logger.debug(f"Preprocessed - shape: {img_array.shape}, dtype: {img_array.dtype}, "
                        f"min: {img_array.min():.4f}, max: {img_array.max():.4f}")
            
            return img_array
        
        def infer(self, frame: np.ndarray) -> np.ndarray:
            """
            í”„ë ˆì„ì—ì„œ í™”ì¬ ê°ì§€ ì¶”ë¡  ìˆ˜í–‰
            
            Returns:
                predictions: ëª¨ë¸ ì¶œë ¥ [1, 25200, 7] (YOLO í˜•ì‹)
                            ê° ì—´: [x, y, w, h, confidence, class_0, class_1]
            """
            if self.engine is None:
                logger.warning("Model not available, skipping inference")
                return np.zeros((1, 25200, 7), dtype=np.float32)
            
            try:
                # ì „ì²˜ë¦¬
                preprocessed = self.preprocess_frame(frame)
                
                # ì¶”ë¡  (DXNN)
                predictions = self.engine.run([preprocessed])
                
                if isinstance(predictions, list):
                    predictions = predictions[0]
                
                # ë””ë²„ê·¸: ì˜ˆì¸¡ í˜•íƒœ í™•ì¸
                if predictions.size > 0:
                    logger.debug(f"Raw predictions shape: {predictions.shape}")
                    if len(predictions.shape) == 3:
                        logger.debug(f"  Max confidence in raw: {np.max(predictions[:, :, 4]):.4f}")
                
                return predictions
            
            except Exception as e:
                logger.error(f"Inference error: {e}")
                return np.zeros((1, 25200, 7), dtype=np.float32)
        
        def extract_max_confidence(self, predictions: np.ndarray) -> float:
            """
            ì˜ˆì¸¡ì—ì„œ ìµœëŒ€ í™”ì¬ ì‹ ë¢°ë„ ì¶”ì¶œ
            
            **ì¤‘ìš”**: Sigmoid ì •ê·œí™”ë¥¼ ë¨¼ì € ì ìš©í•œ í›„,
            ì •ê·œí™”ëœ [0, 1] ë²”ìœ„ì—ì„œ thresholdë¥¼ ì ìš©í•©ë‹ˆë‹¤.
            """
            if predictions.size == 0 or len(predictions.shape) < 3:
                return 0.0
            
            try:
                # Shape í™•ì¸
                logger.debug(f"Predictions shape: {predictions.shape}, dtype: {predictions.dtype}")
                
                # UINT8 ë°ì´í„°ì¸ ê²½ìš° float32ë¡œ ë³€í™˜ ë° ì •ê·œí™” (0-255 â†’ 0-1)
                if predictions.dtype == np.uint8:
                    predictions = predictions.astype(np.float32) / 255.0
                    logger.debug(f"Converted UINT8 to float32 and normalized to [0, 1]")
                
                num_channels = predictions.shape[-1]
                
                if num_channels == 7:
                    # í™”ì¬ ê°ì§€ ëª¨ë¸ (2 í´ë˜ìŠ¤)
                    objectness = predictions[0, :, 4]
                    fire_confidences = predictions[0, :, 5]
                
                elif num_channels == 85:
                    # COCO ëª¨ë¸ (80 í´ë˜ìŠ¤) ë˜ëŠ” ì¼ë°˜ YOLOv7
                    objectness = predictions[0, :, 4]
                    class_confidences = predictions[0, :, 5:]
                    fire_confidences = np.max(class_confidences, axis=1)
                
                else:
                    logger.warning(f"Unknown output format with {num_channels} channels")
                    return 0.0
                
                # ì›ë³¸ raw logit ê°’ ë¶„ì„
                logger.debug(f"Objectness (RAW logit) - min: {objectness.min():.2f}, max: {objectness.max():.2f}, "
                           f"mean: {objectness.mean():.2f}")
                logger.debug(f"Fire confidence (RAW logit) - min: {fire_confidences.min():.2f}, max: {fire_confidences.max():.2f}, "
                           f"mean: {fire_confidences.mean():.2f}")
                
                # âš ï¸ í…ŒìŠ¤íŠ¸: ì•„ê¹Œì™€ ë™ì¼í•˜ê²Œ RAW LOGITì— threshold ì ìš© (Sigmoid ì—†ì´)
                valid_mask = (objectness > self.conf_threshold) & (fire_confidences > self.conf_threshold)
                
                num_valid = np.sum(valid_mask)
                logger.debug(f"Valid detections (RAW logit - objectness > {self.conf_threshold} AND fire_conf > {self.conf_threshold}): {num_valid}")
                
                if not np.any(valid_mask):
                    logger.debug(f"No valid detections (RAW logit mode)")
                    return 0.0
                
                # ìœ íš¨í•œ detectionì˜ ìµœëŒ€ fire confidence (Sigmoid í›„)
                fire_sigmoid = expit(fire_confidences.astype(np.float64))
                max_confidence = float(np.max(fire_sigmoid[valid_mask]))
                logger.debug(f"Max fire confidence (after Sigmoid): {max_confidence:.4f}")
                
                return max_confidence
            
            except Exception as e:
                logger.warning(f"Error extracting confidence: {e}")
                return 0.0
        
        def get_time_averaged_confidence(self) -> float:
            """ì‹œê°„ ê¸°ë°˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°"""
            if not self.confidence_history:
                return 0.0
            
            return float(np.mean(list(self.confidence_history)))
        
        def determine_alert_level(self, avg_confidence: float) -> str:
            """í‰ê·  ì‹ ë¢°ë„ì— ë”°ë¥¸ ì•Œë¦¼ ë“±ê¸‰ ê²°ì •"""
            for level, (min_conf, max_conf, msg) in self.ALERT_LEVEL.items():
                if min_conf <= avg_confidence < max_conf:
                    return level
            return 'HIGH'  # >= 0.65
        
        def log_alert(self, avg_confidence: float, alert_level: str):
            """ì•Œë¦¼ ë¡œê·¸ ì¶œë ¥"""
            current_time = time.time()
            
            # ì•Œë¦¼ ë ˆë²¨ì´ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì¶©ë¶„í•œ ì‹œê°„ì´ ê²½ê³¼í–ˆì„ ë•Œë§Œ ë¡œê·¸
            if (alert_level != self.current_alert_level or 
                current_time - self.last_alert_time > self.alert_duration):
                
                self.current_alert_level = alert_level
                self.last_alert_time = current_time
                
                min_conf, max_conf, msg = self.ALERT_LEVEL[alert_level]
                logger.info(
                    f"{msg} | "
                    f"Avg Confidence: {avg_confidence:.4f} | "
                    f"Detections: {len(self.confidence_history)}"
                )
        
        def draw_info_on_frame(
            self,
            frame: np.ndarray,
            current_confidence: float,
            avg_confidence: float,
            alert_level: str
        ) -> np.ndarray:
            """í”„ë ˆì„ì— ì •ë³´ ë° ì•Œë¦¼ í‘œì‹œ"""
            frame_display = frame.copy()
            h, w = frame_display.shape[:2]
            
            # ë°°ê²½ (ë°˜íˆ¬ëª…)
            overlay = frame_display.copy()
            cv2.rectangle(overlay, (0, 0), (w, 100), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.3, frame_display, 0.7, 0, frame_display)
            
            # í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ì•Œë¦¼ ë“±ê¸‰ë³„)
            alert_colors = {
                'MONITORING': (200, 200, 200),  # íšŒìƒ‰
                'LOW': (0, 165, 255),            # ì£¼í™©ìƒ‰
                'MEDIUM': (0, 255, 255),         # ë…¸ë‘
                'HIGH': (0, 0, 255)              # ë¹¨ê°•
            }
            color = alert_colors.get(alert_level, (200, 200, 200))
            
            # ì •ë³´ í‘œì‹œ
            y_offset = 30
            cv2.putText(
                frame_display,
                f"Current Conf: {current_confidence:.4f}",
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2
            )
            
            y_offset += 30
            cv2.putText(
                frame_display,
                f"Avg Conf ({self.time_window}s): {avg_confidence:.4f}",
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2
            )
            
            y_offset += 30
            min_conf, max_conf, alert_msg = self.ALERT_LEVEL[alert_level]
            alert_msg_short = alert_msg.split('|')[0].strip()
            cv2.putText(
                frame_display,
                f"Alert: {alert_msg_short}",
                (10, y_offset),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                color,
                2
            )
            
            # ì•Œë¦¼ ë“±ê¸‰ë³„ í…Œë‘ë¦¬
            thickness = 3
            cv2.rectangle(frame_display, (0, 0), (w-1, h-1), color, thickness)
            
            return frame_display
        
        def run(self, display: bool = True, output_video: Optional[str] = None):
            """
            ì‹¤ì‹œê°„ í™”ì¬ ê°ì§€ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰
            
            Args:
                display: í™”ë©´ì— í‘œì‹œí• ì§€ ì—¬ë¶€
                output_video: ê²°ê³¼ë¥¼ ì €ì¥í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì €ì¥ ì•ˆ í•¨)
            """
            logger.info("ğŸ¬ Starting fire detection monitoring...")
            
            # ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
            writer = None
            if output_video:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                writer = cv2.VideoWriter(
                    output_video,
                    fourcc,
                    self.fps,
                    (int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                    int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
                )
                logger.info(f"ğŸ“¹ Output video will be saved to: {output_video}")
            
            frame_count = 0
            inference_times = deque(maxlen=30)
            
            try:
                while True:
                    ret, frame = self.cap.read()
                    if not ret:
                        logger.info("End of video or camera disconnected")
                        break
                    
                    frame_count += 1
                    current_time = time.time()
                    
                    # ì¶”ë¡ 
                    infer_start = time.time()
                    predictions = self.infer(frame)
                    infer_time = time.time() - infer_start
                    inference_times.append(infer_time)
                    
                    # ì‹ ë¢°ë„ ì¶”ì¶œ
                    current_confidence = self.extract_max_confidence(predictions)
                    
                    # ì´ë ¥ì— ì €ì¥
                    self.confidence_history.append(current_confidence)
                    self.timestamp_history.append(current_time)
                    
                    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° ë° ì•Œë¦¼ ê²°ì •
                    avg_confidence = self.get_time_averaged_confidence()
                    alert_level = self.determine_alert_level(avg_confidence)
                    
                    # ì•Œë¦¼ ë¡œê·¸
                    self.log_alert(avg_confidence, alert_level)
                    
                    # í”„ë ˆì„ì— ì •ë³´ í‘œì‹œ
                    frame_with_info = self.draw_info_on_frame(
                        frame,
                        current_confidence,
                        avg_confidence,
                        alert_level
                    )
                    
                    # í™”ë©´ í‘œì‹œ
                    if display:
                        cv2.imshow('Fire Detection Monitor', frame_with_info)
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            logger.info("User requested exit")
                            break
                    
                    # ë¹„ë””ì˜¤ ì €ì¥
                    if writer:
                        writer.write(frame_with_info)
                    
                    # ì£¼ê¸°ì  í†µê³„ ì¶œë ¥
                    if frame_count % (self.fps * 5) == 0:  # 5ì´ˆë§ˆë‹¤
                        avg_infer_time = np.mean(list(inference_times))
                        logger.info(
                            f"[Frame {frame_count}] "
                            f"Avg Infer: {avg_infer_time*1000:.2f}ms | "
                            f"FPS: {1/avg_infer_time:.1f}"
                        )
            
            except KeyboardInterrupt:
                logger.info("Interrupted by user")
            
            finally:
                logger.info("ğŸ›‘ Shutting down...")
                self.cap.release()
                if writer:
                    writer.release()
                if display:
                    cv2.destroyAllWindows()
                logger.info(f"Total frames processed: {frame_count}")


def main():
        parser = argparse.ArgumentParser(
            description="Fire Detection Real-time Monitoring"
        )
        parser.add_argument(
            '--model',
            type=str,
            required=True,
            help='Path to DXNN model file (.dxnn)'
        )
        parser.add_argument(
            '--video',
            type=str,
            default='/dev/video0',
            help='Video source (camera: /dev/video0, or video file path)'
        )
        parser.add_argument(
            '--time-window',
            type=float,
            default=3.0,
            help='Time window for averaging confidence (seconds)'
        )
        parser.add_argument(
            '--conf-threshold',
            type=float,
            default=0.5,
            help='Confidence threshold for detection'
        )
        parser.add_argument(
            '--output',
            type=str,
            default=None,
            help='Output video file path (optional)'
        )
        parser.add_argument(
            '--no-display',
            action='store_true',
            help='Disable display window'
        )
        
        args = parser.parse_args()
        
        # ëª¨ë‹ˆí„° ì‹¤í–‰
        monitor = FireDetectionMonitor(
            model_path=args.model,
            video_source=args.video,
            time_window=args.time_window,
            conf_threshold=args.conf_threshold
        )
        
        monitor.run(
            display=not args.no_display,
            output_video=args.output
        )


if __name__ == '__main__':
    main()
